{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qbltlYE_x4ZX"},"source":["<h2>개인 구글 드라이브와 colab 연동</h2>"]},{"cell_type":"code","metadata":{"id":"j6q5Z9pNGA0M","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1695549087510,"user_tz":-540,"elapsed":17946,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"781441fd-5097-43c2-af49-a925189d181c"},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)\n","\n","\"\"\"\n","처음 부분은 불용어를 제거한 경우에 대한 실습 결과입니다.(7점을 위한 것)\n","\n","두 번째 부분은 성능을 추가하기 위해서 한 글자 혹은 두 글자인 단어인 경우와 일부 특수문자를 제거한 경우를 포함시켜 성능을 향상 시킨 실습 결과입니다.(10점을 위한 것)\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\n처음 부분은 불용어를 제거한 경우에 대한 실습 결과입니다.(7점을 위한 것)\\n\\n두 번째 부분은 성능을 추가하기 위해서 한 글자 혹은 두 글자인 단어인 경우와 일부 특수문자를 제거한 경우를 포함시켜 성능을 향상 시킨 실습 결과입니다.(10점을 위한 것)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"PlXCd1UpzDLL"},"source":["<h2>\"SMSSpamCollection\" 데이터를 읽고 문장과 정답을 분리하여 각 리스트에 저장</h2>\n","\n","<pre>\n","<b>1. 데이터의 형태(SMSSpamCollection)</b>\n","  라벨(스팸 또는 햄) \\t(tab) 문장\n","  \n","  위와 같은 형태로 저장되어 있음\n","  \n","  예시)\n","    ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n","    spam\\tCustomer service annoncement. You have a New Years delivery waiting for you. Please call 07046744435 now to arrange delivery\n","    ...\n","  \n","  따라서 입력 데이터를 읽고 \\t을 기준으로 입력 문장을 분리한 후에 문장과 라벨을 각각 x_data, y_data 리스트에 저장\n","  \n","<b>2. 입력 데이터 전체를 사용하지 않고 100개만 추출해서 사용</b>\n","\n","<b>3. x_data, y_data 형태</b>\n","  x_data = [ 문장1, 문장2, 문장3, ... 문장100]\n","  y_data = [ 문장1의 라벨, 문장2의 라벨, 문장3의 라벨, ... 문장100의 라벨]\n","</pre>"]},{"cell_type":"code","metadata":{"id":"gUuFzwfHGFrq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695550118822,"user_tz":-540,"elapsed":9,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"df33f527-b9eb-46f9-fd43-b5196d01dae0"},"source":["import numpy as np\n","\n","file_path = \"/gdrive/MyDrive/Colab/Week04/SMSSpamCollection.dat\"\n","\"\"\"\n","svm은 binary classification에서 가장 좋은 효율\n","만약 여러 개라면 A와 나머지, B와 나머지 같은 방식을 이용\n","\"\"\"\n","\n","# 파일 읽기\n","x_data, y_data = [], []\n","with open(file_path,'r',encoding='utf8') as inFile:\n","  lines = inFile.readlines()\n","\n","lines = lines[:100]  #100개만 잘라서 라인 단위로 사용!\n","for line in lines:\n","  line = line.strip().split('\\t')#tab 단위로 분리. strip 앞뒤 화이트 스페이스 제거하는 함수\n","  sentence, label = line[1], line[0]#sentence와 label(정답)을 분리\n","  x_data.append(sentence)#sentence는 x 데이터\n","  y_data.append(label)#정답인 label은 y 데이터\n","\n","print(\"x_data의 개수 : \" + str(len(x_data)))\n","print(\"y_data의 개수 : \" + str(len(y_data)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_data의 개수 : 100\n","y_data의 개수 : 100\n"]}]},{"cell_type":"markdown","metadata":{"id":"3R9OE2Cp1jRX"},"source":["<h2>Tokenizer 라이브러리를 사용하여 입력 문장을 index로 치환</h2>\n","\n","<pre>\n","<b>1. tokenizer.fit_on_texts(data) 함수를 이용하여 각 단어를 index로 치환하기 위한 딕셔너리 생성</b>\n","   생성된 딕셔너리는 tokenizer 객체 안에 저장됨\n","  \n","  tokenizer.fit_on_texts(data)\n","  args\n","    data : 문자열 element를 가지고 있는 리스트\n","  return\n","    X\n","    \n","  딕셔너리 예시)\n","    {'to': 1, 'i': 2, 'you': 3, 'a': 4, 'the': 5, 'and': 6, 'for': 7 ... }\n","    \n","<b>2. tokenizer.texts_to_sequences(data) 함수를 이용하여 문장 안에 있는 단어들을 index로 치환</b>\n","\n","  tokenizer.texts_to_sequence(data)\n","  args\n","    data : 문자열 element를 가지고 있는 리스트\n","  return :\n","    indexing 된 리스트\n","    \n","  indexing 예시)\n","    x_data indexing 하기 전 : Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n","    x_data indexing 하기 후 : [38, 93, 239, 240, 241, 242, 53, 11, 243, 72, 94, 244, 245, 126, 246, 247, 73, 74, 248, 127]\n","    y_data indexing 하기 전 : ham\n","    y_data indexing 하기 후 : 1\n","</pre>"]},{"cell_type":"code","metadata":{"id":"L8kEaEkA02Qz"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YEagO2Q0GOBM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695550118822,"user_tz":-540,"elapsed":6,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"9fbf8758-4d0f-4cfa-ab4e-b82c87767f9e"},"source":["from keras.preprocessing.text import Tokenizer\n","import nltk\n","\n","tokenizer = Tokenizer()#스페이스 단위로 Token으로 취급\n","\n","\n","# spam, ham 라벨을 대응하는 index로 치환하기위한 딕셔너리\n","label2index_dict = {'spam':0, 'ham':1}\n","\n","# indexing 한 데이터를 넣을 리스트 선언\n","indexing_x_data, indexing_y_data = [], []\n","#숫자로 받을 리스트\n","\n","for label in y_data:\n","  indexing_y_data.append(label2index_dict[label])\n","#label을 딕셔너리를 통해서 리스트에 대입해서 변환\n","\n","# x_data를 사용하여 딕셔너리 생성\n","tokenizer.fit_on_texts(x_data)\n","#문장인 x_data는 단어가 굉장히 많은데 이 함수를 통해서 unique하게 sort해서 중복을 제거하고 번호로 딕셔너리를 통해 indexing하는 것을 vocabularay라고 함!\n","#이 vocabularay의 원소가 한 개당 1차원으로 svm은 인식\n","nltk.download('stopwords')\n","stopwordlist = nltk.corpus.stopwords.words('english')\n","\n","i=0\n","flag=False\n","for sentence in x_data:\n","  sentenceList = sentence.split()\n","  newSentenceList=[]\n","  for word in sentenceList:\n","    if word.lower() in stopwordlist: #불용어 체크해서 해당 단어가 불용어인 경우에는 제외\n","      continue\n","    else:\n","      newSentenceList.append(word)\n","      flag=True\n","  if flag==True:\n","    flag=False\n","    newSentence = ' '.join(map(str, newSentenceList))\n","    x_data[i]=newSentence\n","  i+=1\n","# x_data에 있는 각 문장의 단어들을 대응하는 index로 치환하고 그 결과값을 indexing_x_data에 저장\n","indexing_x_data = tokenizer.texts_to_sequences(x_data)\n","#만든 딕셔너리를 활용해서 숫자들로 인덱싱해서 리스트로 변환\n","\n","print(\"x_data indexing 하기 전 : \" + str(x_data[0]))\n","print(\"x_data indexing 하기 후 : \" + str(indexing_x_data[0]))\n","print(\"y_data indexing 하기 전 : \" + str(y_data[0]))\n","print(\"y_data indexing 하기 후 : \" + str(indexing_y_data[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_data indexing 하기 전 : Go jurong point, crazy.. Available bugis n great world la e buffet... Cine got amore wat...\n","x_data indexing 하기 후 : [38, 239, 240, 241, 242, 243, 72, 94, 244, 245, 126, 246, 247, 74, 248, 127]\n","y_data indexing 하기 전 : ham\n","y_data indexing 하기 후 : 1\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"nN5GGyQI_IpT"},"source":["<h2>SVM 모델 학습</h2>\n","\n","<pre>\n","<b>1. 데이터의 문장 길이를 고정된 길이로 변환</b>\n","  예제 코드에서는 60으로 맞추어 변환\n","  \n","  문장 길이가 60 초과인 경우 뒷 부분 제거\n","  문장 길이가 60 미만인 경우 나머지 부분을 0으로 채움\n","  \n","  예시)\n","    문장 길이를 5로 맞추고자 할 경우\n","    \n","    문장 길이가 5보다 큰 경우\n","    문장 : 나는 어제 집에서 저녁으로 김치찌개를 먹었다, indexing_문장 : 38, 93, 239, 240, 241, 242\n","    38, 93, 239, 240, 241, 242 -> 38, 93, 239, 240, 241\n","    \n","    문장 길이가 5보다 작은 경우\n","    문장 : 나는 김치찌개를 좋아해, indexing_문장 : 74, 248, 127\n","    74, 248, 127 -> 74, 248, 127, 0, 0\n","    \n","<b>2. 입력 데이터를 9 대 1 비율로 나누어 학습, 평가에 사용</b>\n","  train_x = [ 문장1, 문장2, 문장3, ... 문장90]\n","  train_y = [ 문장1의 라벨, 문장2의 라벨, 문장3의 라벨, ... 문장90의 라벨]\n","  test_x = [ 문장91, 문장92, 문장93, ... 문장100]\n","  test_y = [ 문장91의 라벨, 문장92의 라벨, 문장93의 라벨, ... 문장100의 라벨]\n","  \n","<b>3. svm.fit(x, y) 함수를 사용하여 SVM 모델 학습</b>\n","  svm.fit(x, y)\n","  args\n","    x : indexing 된 문장들이 있는 리스트\n","    y : x의 각 문장에 대응하는 라벨이 있는 리스트\n","  return :\n","    X\n","</pre>"]},{"cell_type":"code","metadata":{"id":"RYNBrDnzGO-5","colab":{"base_uri":"https://localhost:8080/","height":148},"executionInfo":{"status":"ok","timestamp":1695550122855,"user_tz":-540,"elapsed":850,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"e1159a79-708a-4303-971b-d4a10a65afcc"},"source":["from sklearn.svm import SVC#SVClassification만 사용!\n","\n","# 문장의 길이를 max_length으로 맞춰 변환\n","max_length = 60\n","for index in range(len(indexing_x_data)):#모든 인덱스에 대해서 반복! 모든 데이터를 같은 길이로 보정\n","#테스트 데이터가 얼마나 긴 게 들어올 지는 모르나 한정된 길이만 기준으로 checking 해야함\n","  length = len(indexing_x_data[index])\n","\n","  if(length > max_length):#길이가 넘어가면 자름\n","    indexing_x_data[index] = indexing_x_data[index][:max_length]\n","  elif(length < max_length):#아니면 임의의 값인 0으로 추가 이를 padding이라고 함\n","    indexing_x_data[index] = indexing_x_data[index] + [0]*(max_length-length)\n","\n","\n","# 전체 데이터를 9:1의 비율로 나누어 학습 및 평가 데이터로 사용\n","number_of_train = int(len(indexing_x_data)*0.9)\n","\n","#train data랑 test data 분리\n","train_x = indexing_x_data[:number_of_train]\n","train_y = indexing_y_data[:number_of_train]\n","test_x = indexing_x_data[number_of_train:]\n","test_y = indexing_y_data[number_of_train:]\n","\n","print(\"train_x의 개수 : \" + str(len(train_x)))\n","print(\"train_y의 개수 : \" + str(len(train_y)))\n","print(\"test_x의 개수 : \" + str(len(test_x)))\n","print(\"test_y의 개수 : \" + str(len(test_y)))\n","\n","svm = SVC(kernel='linear', C=1e10)#svm에 kernel function을 linear로 설정하고 C는 margin 내부의 Slack을 위한 변수로 error 허용 SVC 객체 담기\n","#차원이 굉장히 큰 문제인 경우 linear kernel function 사용! -> 여기서는 단어 한 개가 1차원이라서 차원이 굉장히 크다!\n","#차원이 작거나 100차원이내의 kernel이면 RBF나 다른 kernel function이 성능이 좋다.\n","svm.fit(train_x, train_y)#학습 시작!"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_x의 개수 : 90\n","train_y의 개수 : 90\n","test_x의 개수 : 10\n","test_y의 개수 : 10\n"]},{"output_type":"execute_result","data":{"text/plain":["SVC(C=10000000000.0, kernel='linear')"],"text/html":["<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10000000000.0, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10000000000.0, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"l8Ez7hULOckE"},"source":["<h2>SVM 모델을 이용한 평가</h2>\n","\n","<pre>\n","<b>1. svm.predict(data) 함수를 사용하여 SVM 모델을 이용하여 평가</b>\n","  \n","  svm.predict(data)\n","  args\n","    data : indexing 된 문장들이 있는 리스트\n","  return :\n","    입력 문장들에 대한 모델의 출력 라벨 리스트\n","    \n","<b>2. 성능 측정</b>\n","  정답 라벨과 모델의 출력 라벨을 비교하여 성능 측정\n","  \n","<b>3. tokenizer.sequences_to_texts(data) 함수를 이용하여 indexing 된 데이터를 단어로 치환</b>\n","\n","  tokenizer.sequences_to_texts(data)\n","  args\n","    data : indexing 된 리스트\n","  return :\n","    단어로 치환된 리스트\n","    \n","  예시)\n","    [38, 93, 239, 240, 241, 242, 53, 11, 243, 72, 94, 244, 245, 126, 246, 247, 73, 74, 248, 127] -> Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n","    \n","<b>4. 입력 문장에 대한 모델의 출력과 정답 출력</b>\n","\n","</pre>"]},{"cell_type":"code","metadata":{"id":"gONe3GnfGQcu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695550126200,"user_tz":-540,"elapsed":325,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"a828e835-0968-429a-b618-676c83d0bbc8"},"source":["predict = svm.predict(test_x)#test_x는 test할 데이터로 예측하고 그 결과를 predict 변수에 담기!(리스트 단위 반환)\n","\n","correct_count = 0\n","for index in range(len(predict)):\n","  if(test_y[index] == predict[index]):#예측으로 나온 값이 정답과 비교\n","    correct_count += 1\n","\n","accuracy = 100.0*correct_count/len(test_y)\n","\n","\n","print(\"Accuracy: \" + str(accuracy))\n","\n","index2label = {0:\"spam\", 1:\"ham\"}\n","#다시 index를 label로 변환\n","test_x_word = tokenizer.sequences_to_texts(test_x)\n","#다시 index를 sentence로 변환\n","for index in range(len(test_x_word)):\n","  print()\n","  print(\"문장 : \", test_x_word[index])\n","  print(\"정답 : \", index2label[test_y[index]])\n","  print(\"모델 출력 : \", index2label[predict[index]])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 60.0\n","\n","문장 :  yeah do don‘t stand close tho you‘ll catch something\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  sorry pain ok meet another night spent late afternoon casualty means done stuff42moro includes time sheets that sorry\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  smile pleasure smile pain smile trouble pours like rain smile sum1 hurts u smile becoz someone still loves see u smiling\n","정답 :  ham\n","모델 출력 :  spam\n","\n","문장 :  please call customer service representative 0800 169 6031 10am 9pm guaranteed ￡1000 cash ￡5000 prize\n","정답 :  spam\n","모델 출력 :  ham\n","\n","문장 :  havent planning buy later check already lido got 530 show e afternoon u finish work already\n","정답 :  ham\n","모델 출력 :  spam\n","\n","문장 :  free ringtone waiting collected simply text password mix 85069 verify get usher britney fml po box 5249 mk17 92h 450ppw 16\n","정답 :  spam\n","모델 출력 :  spam\n","\n","문장 :  watching telugu movie wat abt u\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  see finish loads loans pay\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  hi wk ok hols now yes bit run forgot hairdressers appointment four need get home n shower beforehand cause prob u\n","정답 :  ham\n","모델 출력 :  spam\n","\n","문장 :  see cup coffee animation\n","정답 :  ham\n","모델 출력 :  ham\n"]}]},{"cell_type":"code","metadata":{"id":"jGk8ia1cSc66","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695550027447,"user_tz":-540,"elapsed":277,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"4dfb87ed-1f59-496c-acbb-84cc26e90e21"},"source":["import nltk\n","\n","nltk.download('stopwords')\n","\"\"\"\n","불용어 리스트를 참고해서 입력 문장에서 불용어를 제거한 SVM 기반 스팸 메일 필터를 구현하기!\n","불용어는 사용할 필요 없는 말!(a, the, 은/는/이/가 같은 리스트를 stopwordlist인 불용어리스트라고 한다!)\n","즉, 불용어는 정보 검색에 대해서는 필요없으니 여기서 단어 1개가 1개의 차원이니까\n","불용어를 없앤다는 것은 곧 차원을 줄인다는 것!\n","\n","feature를 추가한다면\n","스팸을 조사해서 쓸데없는 말을 제거하는 것말고 중요한 단어를 선택하는 방법인 카이스퀘어통계량을 이용 가능\n","한 단어가 아닌 두 단어를 기준으로 1차원을 응용해서 차원을 줄이기\n","mutual impormation같은 상호 정보량을 이용해서 차원을 줄이기\n","\n","\"\"\"\n","print('영어 불용어 갯수 : ', len(nltk.corpus.stopwords.words('english')))\n","print(nltk.corpus.stopwords.words('english')[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["영어 불용어 갯수 :  179\n","['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["\"\"\"\n","여기서부터는 성능 개선을 위한 Feature 추가입니다.\n","\"\"\"\n","\n","import numpy as np\n","\n","file_path = \"/gdrive/MyDrive/Colab/Week04/SMSSpamCollection.dat\"\n","\"\"\"\n","svm은 binary classification에서 가장 좋은 효율\n","만약 여러 개라면 A와 나머지, B와 나머지 같은 방식을 이용\n","\"\"\"\n","\n","# 파일 읽기\n","x_data, y_data = [], []\n","with open(file_path,'r',encoding='utf8') as inFile:\n","  lines = inFile.readlines()\n","\n","lines = lines[:100]  #100개만 잘라서 라인 단위로 사용!\n","for line in lines:\n","  line = line.strip().split('\\t')#tab 단위로 분리. strip 앞뒤 화이트 스페이스 제거하는 함수\n","  sentence, label = line[1], line[0]#sentence와 label(정답)을 분리\n","  x_data.append(sentence)#sentence는 x 데이터\n","  y_data.append(label)#정답인 label은 y 데이터\n","\n","print(\"x_data의 개수 : \" + str(len(x_data)))\n","print(\"y_data의 개수 : \" + str(len(y_data)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04QYjDqjmPtF","executionInfo":{"status":"ok","timestamp":1695550131964,"user_tz":-540,"elapsed":347,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"afb119ed-fc30-4030-c2fb-afea91a6c2a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_data의 개수 : 100\n","y_data의 개수 : 100\n"]}]},{"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","import nltk\n","\n","tokenizer = Tokenizer()#스페이스 단위로 Token으로 취급\n","\n","\n","# spam, ham 라벨을 대응하는 index로 치환하기위한 딕셔너리\n","label2index_dict = {'spam':0, 'ham':1}\n","\n","# indexing 한 데이터를 넣을 리스트 선언\n","indexing_x_data, indexing_y_data = [], []\n","#숫자로 받을 리스트\n","\n","for label in y_data:\n","  indexing_y_data.append(label2index_dict[label])\n","#label을 딕셔너리를 통해서 리스트에 대입해서 변환\n","\n","# x_data를 사용하여 딕셔너리 생성\n","tokenizer.fit_on_texts(x_data)\n","#문장인 x_data는 단어가 굉장히 많은데 이 함수를 통해서 unique하게 sort해서 중복을 제거하고 번호로 딕셔너리를 통해 indexing하는 것을 vocabularay라고 함!\n","#이 vocabularay의 원소가 한 개당 1차원으로 svm은 인식\n","nltk.download('stopwords')\n","stopwordlist = nltk.corpus.stopwords.words('english')\n","\n","i=0\n","flag=False\n","for sentence in x_data:\n","  sentenceList = sentence.split()\n","  newSentenceList=[]\n","  for word in sentenceList:\n","    if (len(word) == 1):# 한 글자는 상대적으로 큰 의미가 없으니까 학습에서 제거한다. 이렇게 하면 포함되는 word수가 적어지니 차원의 수가 적어진다.\n","        continue\n","    if (word.lower() in stopwordlist):\n","      #불용어 체크해서 해당 단어가 불용어인 경우에는 제외\n","      continue\n","    else:\n","      word = word.replace('.', '').replace(',', '').replace('#','').replace('!','').replace('@','')\n","      #일부 많이 사용되는 특수 문자는 상대적으로 큰 의미가 없고 오히려 같은 단어이지만 일부 특수문자로 구별되는 경우를 방지해 차원의 수를 줄인다.\n","      #즉, apple과 apple!같은 경우 같은 단어이지만 !라는 특수문자로 인해서 다른 단어로 분류되어 차원의 수를 높이는 경우를 방지하기 위함이다.\n","      newSentenceList.append(word)\n","      flag=True\n","  if flag==True:\n","    flag=False\n","    newSentence = ' '.join(map(str, newSentenceList))\n","    x_data[i]=newSentence\n","  i+=1\n","# x_data에 있는 각 문장의 단어들을 대응하는 index로 치환하고 그 결과값을 indexing_x_data에 저장\n","indexing_x_data = tokenizer.texts_to_sequences(x_data)\n","#만든 딕셔너리를 활용해서 숫자들로 인덱싱해서 리스트로 변환\n","\n","print(\"x_data indexing 하기 전 : \" + str(x_data[0]))\n","print(\"x_data indexing 하기 후 : \" + str(indexing_x_data[0]))\n","print(\"y_data indexing 하기 전 : \" + str(y_data[0]))\n","print(\"y_data indexing 하기 후 : \" + str(indexing_y_data[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bgdTXeRfmQVE","executionInfo":{"status":"ok","timestamp":1695550133674,"user_tz":-540,"elapsed":276,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"5bacb1a4-430d-4dec-ef25-5a5629fb9712"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_data indexing 하기 전 : Go jurong point crazy Available bugis great world la buffet Cine got amore wat\n","x_data indexing 하기 후 : [38, 239, 240, 241, 242, 243, 94, 244, 245, 246, 247, 74, 248, 127]\n","y_data indexing 하기 전 : ham\n","y_data indexing 하기 후 : 1\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["from sklearn.svm import SVC#SVClassification만 사용!\n","\n","# 문장의 길이를 max_length으로 맞춰 변환\n","max_length = 60\n","for index in range(len(indexing_x_data)):#모든 인덱스에 대해서 반복! 모든 데이터를 같은 길이로 보정\n","#테스트 데이터가 얼마나 긴 게 들어올 지는 모르나 한정된 길이만 기준으로 checking 해야함\n","  length = len(indexing_x_data[index])\n","\n","  if(length > max_length):#길이가 넘어가면 자름\n","    indexing_x_data[index] = indexing_x_data[index][:max_length]\n","  elif(length < max_length):#아니면 임의의 값인 0으로 추가 이를 padding이라고 함\n","    indexing_x_data[index] = indexing_x_data[index] + [0]*(max_length-length)\n","\n","\n","# 전체 데이터를 9:1의 비율로 나누어 학습 및 평가 데이터로 사용\n","number_of_train = int(len(indexing_x_data)*0.9)\n","\n","#train data랑 test data 분리\n","train_x = indexing_x_data[:number_of_train]\n","train_y = indexing_y_data[:number_of_train]\n","test_x = indexing_x_data[number_of_train:]\n","test_y = indexing_y_data[number_of_train:]\n","\n","print(\"train_x의 개수 : \" + str(len(train_x)))\n","print(\"train_y의 개수 : \" + str(len(train_y)))\n","print(\"test_x의 개수 : \" + str(len(test_x)))\n","print(\"test_y의 개수 : \" + str(len(test_y)))\n","\n","svm = SVC(kernel='linear', C=1e10)#svm에 kernel function을 linear로 설정하고 C는 margin 내부의 Slack을 위한 변수로 error 허용 SVC 객체 담기\n","#차원이 굉장히 큰 문제인 경우 linear kernel function 사용! -> 여기서는 단어 한 개가 1차원이라서 차원이 굉장히 크다!\n","#차원이 작거나 100차원이내의 kernel이면 RBF나 다른 kernel function이 성능이 좋다.\n","svm.fit(train_x, train_y)#학습 시작!"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148},"id":"yQkOTa_cmQhr","executionInfo":{"status":"ok","timestamp":1695550135604,"user_tz":-540,"elapsed":595,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"0eab4149-573c-409d-add9-12673730e1c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_x의 개수 : 90\n","train_y의 개수 : 90\n","test_x의 개수 : 10\n","test_y의 개수 : 10\n"]},{"output_type":"execute_result","data":{"text/plain":["SVC(C=10000000000.0, kernel='linear')"],"text/html":["<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10000000000.0, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10000000000.0, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["predict = svm.predict(test_x)#test_x는 test할 데이터로 예측하고 그 결과를 predict 변수에 담기!(리스트 단위 반환)\n","\n","correct_count = 0\n","for index in range(len(predict)):\n","  if(test_y[index] == predict[index]):#예측으로 나온 값이 정답과 비교\n","    correct_count += 1\n","\n","accuracy = 100.0*correct_count/len(test_y)\n","\n","\n","print(\"Accuracy: \" + str(accuracy))\n","\n","index2label = {0:\"spam\", 1:\"ham\"}\n","#다시 index를 label로 변환\n","test_x_word = tokenizer.sequences_to_texts(test_x)\n","#다시 index를 sentence로 변환\n","for index in range(len(test_x_word)):\n","  print()\n","  print(\"문장 : \", test_x_word[index])\n","  print(\"정답 : \", index2label[test_y[index]])\n","  print(\"모델 출력 : \", index2label[predict[index]])\n","\n","  \"\"\"\n","  기존 불용어를 제외하고\n","  추가로 한 글자인 단어를 제외하고\n","  최종적으로 남은 단어들의 일부 의미없는 특수문자들을 제거한 결과 성능이 향상되었다.\n","  \"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oErAsXpumQrY","executionInfo":{"status":"ok","timestamp":1695550137196,"user_tz":-540,"elapsed":314,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"8881606d-74e9-44b8-f5e3-9d673260d530"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 90.0\n","\n","문장 :  yeah do don‘t stand close tho you‘ll catch something\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  sorry pain ok meet another night spent late afternoon casualty means done stuff42moro includes time sheets that sorry\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  smile pleasure smile pain smile trouble pours like rain smile sum1 hurts smile becoz someone still loves see smiling\n","정답 :  ham\n","모델 출력 :  spam\n","\n","문장 :  please call customer service representative 0800 169 6031 10am 9pm guaranteed ￡1000 cash ￡5000 prize\n","정답 :  spam\n","모델 출력 :  spam\n","\n","문장 :  havent planning buy later check already lido got 530 show afternoon finish work already\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  free ringtone waiting collected simply text password mix 85069 verify get usher britney fml po box 5249 mk17 92h 450ppw 16\n","정답 :  spam\n","모델 출력 :  spam\n","\n","문장 :  watching telugu abt u\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  see finish loads loans pay\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  hi wk ok hols now yes bit run forgot hairdressers appointment four need get home shower beforehand cause prob u\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  see cup coffee animation\n","정답 :  ham\n","모델 출력 :  ham\n"]}]}]}