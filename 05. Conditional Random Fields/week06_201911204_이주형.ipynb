{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YYKwldBwVXIW"},"source":["<h2>개인 구글 드라이브와 colab 연동 </h2>"]},{"cell_type":"code","metadata":{"id":"5o0lh-JLURY7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696673140884,"user_tz":-540,"elapsed":17820,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"aa1decd9-0e7e-4c85-861d-2b4d07fe8a8a"},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"junjuA4pVM5n"},"source":["<h2>라이브러리 설치 </h2>"]},{"cell_type":"code","metadata":{"id":"WwzrDnJYmV3Z","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1696674384884,"user_tz":-540,"elapsed":8498,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"fcc66417-b08a-4b5d-a5c9-cc1b8dade212"},"source":["!pip install sklearn-crfsuite\n","\n","\"\"\"\n","sklearn에서 crfsuite만 install하고 싶은 경우\n","이 때 !는 local 컴퓨터해서 해당 명령어 실행하라는 의미\n","즉, local 컴퓨터에 pip가 있어야 함\n","\n","단점은 구글 코랩 환경에서는 시간이 지나면 삭제가 됨. 그러면 재설치해야함\n","local에서는 삭제가 안됨\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (0.3.6)\n","Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (0.9.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (1.16.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (0.9.0)\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (4.66.1)\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\nsklearn에서 crfsuite만 install하고 싶은 경우\\n이 때 !는 local 컴퓨터해서 해당 명령어 실행하라는 의미\\n즉, local 컴퓨터에 pip가 있어야 함\\n\\n단점은 구글 코랩 환경에서는 시간이 지나면 삭제가 됨. 그러면 재설치해야함\\nlocal에서는 삭제가 안됨\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"0VJD-PF6dYfb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696674715063,"user_tz":-540,"elapsed":330189,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"a4bdef14-097f-4d71-f0f3-0655cfce99a9"},"source":["\"\"\"\n","과제 실습 풀이 설명\n","\n","해당 과제에서 바뀐 부분은 이 부분만 존재하고 나머지 부분은 동일합니다.\n","추가로 변형한 부분을 위주로 설명드리겠습니다.\n","\n","우선 json과 파일 경로 관리를 위한 라이브러리를 import합니다.\n","그리고 우선 수업에서 다운로드하라는 데이터를 다운로드하고 그 중에서 5가지를 임의로 골라서 구글 드라이브 해당 파일과 동일한 위치에 data라는 폴더를 생성하고 그 안에 다 넣습니다.\n","IT_과학 도메인을 SC로 표현하고 비율을 0.1로 주고 문화(CU), 여성복지(WO), 교육(ED), 스포츠(SP)를 각각 비율을 적용하고 해당 파일 위치도 제공하는데 해당 도메인 내에 json 파일이 되게 많습니다.\n","그래서 해당 파일 경로는 우선 도메인 내의 모든 json 파일로 설정합니다.\n","\n","한 json 파일에도 sentence가 되게 여러가지 존재해서 뽑아낼 수 있지만 저는 도메인 비율별로 즉, 1만개 데이터를 뽑게 되면 SC에서는 1000개의 json 파일을 추출해서 해당 도메인의 각 json 파일마다 sentence 1개를 추출해서 데이터로 모으는 방식입니다.\n","\n","그 이후에 각 도메인 비율에 맞게 json 파일을 불러오고 해당 json 파일을 무작위로 선출합니다.\n","그리고 선출된 json 파일 각각마다 첫 번째 sentence를 추출해서 단어 단위로 추출하고 그 단어마다 B와 I를 알맞게 출력합니다.\n","그리고 해당 sentence를 기준으로 음절단위로 자르고 B와 I로 태그 표시한 것을 튜플을 이용해서  datas에 넣습니다.\n","이를 모든 json 폴더 경로에 대해서 모두 수행합니다.\n","\n","모두 수행한 결과의 data를 한 번 섞습니다.\n","\n","모두 적용했으면 90%는 train data로 사용합니다.\n","\"\"\"\n","\n","import json\n","import glob\n","import random\n","import sklearn_crfsuite\n","from sklearn_crfsuite import metrics\n","\n","# 도메인 비율 정의 (예: 도메인 A가 30%, 도메인 B가 40%, 도메인 C가 30%)\n","domain_ratios = {\n","    \"SC\": 0.1,\n","    \"CU\": 0.15,\n","    \"WO\": 0.25,\n","    \"ED\": 0.25,\n","    \"SP\": 0.25,\n","}\n","\n","# JSON 파일이 있는 폴더의 경로 설정\n","folder_paths = {\n","    \"SC\": \"/gdrive/MyDrive/Colab/Week06/data/SC/*.json\",\n","    \"CU\": \"/gdrive/MyDrive/Colab/Week06/data/CU/*.json\",\n","    \"WO\": \"/gdrive/MyDrive/Colab/Week06/data/WO/*.json\",\n","    \"ED\": \"/gdrive/MyDrive/Colab/Week06/data/ED/*.json\",\n","    \"SP\": \"/gdrive/MyDrive/Colab/Week06/data/SP/*.json\",\n","}\n","\n","# 데이터를 저장할 리스트\n","datas = []\n","\n","# 각 도메인에 대해 JSON 파일을 불러오고 \"sentence\" 추출\n","for domain, ratio in domain_ratios.items():\n","    json_files = glob.glob(folder_paths.get(domain,\"\"))  # 도메인에 해당하는 JSON 파일 목록 가져오기\n","    # 파일 수에 비례하도록 해당 도메인의 데이터 수 계산\n","    num_datas_to_select = int(ratio * 10000)\n","\n","    # 데이터를 무작위로 선택 (num_datas_to_select를 데이터 리스트의 길이 미만으로 조정)\n","    selected_json_files = random.sample(json_files, num_datas_to_select)\n","\n","    # 경로내 json 파일을 열고 작업 수행\n","    for json_file in selected_json_files:\n","        with open(json_file, \"r\", encoding=\"utf8\") as file:\n","            data = json.load(file)\n","\n","            #해당 json 파일에 대해서 첫 번째 sentence를 추출\n","            first_entity = data.get(\"named_entity\", [{}])[0]\n","            first_sentence_obj = first_entity.get(\"title\", [{}])[0] or first_entity.get(\"content\", [{}])[0] or first_entity.get(\"subtitle\", [{}])[0]\n","            first_sentence = first_sentence_obj.get(\"sentence\", \"\")\n","\n","            #추출한 문장을 단어 단위로 쪼개기\n","            words = first_sentence.split()\n","            tags = []\n","            # 각 단어에 대해 태그 할당(B,I)\n","            for word in words:\n","                # 첫 글자에 \"B\" 태그 할당\n","                tags.append(\"B\")\n","                # 나머지 글자에 \"I\" 태그 할당\n","                for _ in range(len(word) - 1):\n","                    tags.append(\"I\")\n","\n","            #튜플로 대입 후 datas에 추가하기\n","            eumjeol_sequence, label = list(first_sentence.strip().replace(' ','')), tags\n","            datas.append((eumjeol_sequence, label))\n","\n","# 데이터를 섞기 (무작위로 데이터를 섞음)\n","number_of_train_datas = int(len(datas)*0.9)\n","\n","train_datas = datas[:number_of_train_datas]\n","test_datas = datas[number_of_train_datas:]\n","\n","print(\"train_datas 개수 : \" + str(len(train_datas)))\n","print(\"test_datas 개수 : \" + str(len(test_datas)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_datas 개수 : 9000\n","test_datas 개수 : 1000\n"]}]},{"cell_type":"markdown","metadata":{"id":"SoVhuFogkT36"},"source":["<pre>\n","<h2> 1. 문장의 각 음절을 crf 모델의 입력으로 사용 할 수 있도록 자질화 </h2>\n","  \"BOS\" : 시작 음절인지 여부\n","  \"EOS\" : 마지막 음절인지 여부\n","  \"WORD\" : 기준 음절\n","  \"IS_DIGIT\" : 기준 음절이 숫자인지 여부\n","  \"-1_WORD\" : 기준 음절의 왼쪽 첫번째 음절\n","  \"-2_WORD\" : 기준 음절의 왼쪽 두번째 음절\n","  \"+1_WORD\" : 기준 음절의 오른쪽 첫번째 음절\n","  \"+2_WORD\" : 기준 음절의 오른쪽 두번째 음절\n","\n","  1.1 예시) [\"나\", \"는\", \"사\", \"과\", \"가\", \"좋\", \"아\"]\n","            ->\n","            [ { \"BOS\":True, \"EOS\":False, \"WORD\":\"나\", \"IS_DIGIT\":False, \"+1_WORD\":\"는\", \"+2_WORD\":\"사\" },\n","    { \"BOS\":False, \"EOS\":False, \"WORD\":\"는\", \"IS_DIGIT\":False, \"-1_WORD\":\"나\", \"+1_WORD\":\"사\", \"+2_WORD\":\"과\" },\n","    { \"BOS\":False, \"EOS\":False, \"WORD\":\"사\", \"IS_DIGIT\":False, \"-2_WORD\":\"나\", \"-1_WORD\":\"는\", \"+1_WORD\":\"과\", \"+2_WORD\":\"가\" }, ... ]\n","    \n","    나 -> { \"BOS\":True, \"EOS\":False, \"WORD\":\"나\", \"IS_DIGIT\":False, \"+1_WORD\":\"는\", \"+2_WORD\":\"사\" }\n","    는 -> { \"BOS\":False, \"EOS\":False, \"WORD\":\"는\", \"IS_DIGIT\":False, \"-1_WORD\":\"나\", \"+1_WORD\":\"사\", \"+2_WORD\":\"과\" }\n","    사 -> { \"BOS\":False, \"EOS\":False, \"WORD\":\"사\", \"IS_DIGIT\":False, \"-2_WORD\":\"나\", \"-1_WORD\":\"는\", \"+1_WORD\":\"과\", \"+2_WORD\":\"가\" }\n","    과 -> { \"BOS\":False, \"EOS\":False, \"WORD\":\"과\", \"IS_DIGIT\":False, \"-2_WORD\":\"는\", \"-1_WORD\":\"사\", \"+1_WORD\":\"가\", \"+2_WORD\":\"좋\" }\n","    가 -> { \"BOS\":False, \"EOS\":False, \"WORD\":\"가\", \"IS_DIGIT\":False, \"-2_WORD\":\"사\", \"-1_WORD\":\"과\", \"+1_WORD\":\"좋\", \"+2_WORD\":\"아\" }\n","    좋 -> { \"BOS\":False, \"EOS\":False, \"WORD\":\"좋\", \"IS_DIGIT\":False, \"-2_WORD\":\"과\", \"-1_WORD\":\"가\", \"+1_WORD\":\"아\" }\n","    아 -> { \"BOS\":False, \"EOS\":True, \"WORD\":\"아\", \"IS_DIGIT\":False, \"-2_WORD\":\"가\", \"-1_WORD\":\"좋\" }\n","<h2> 2. 자질화한 데이터와 해당 데이터의 라벨을 분리하여 각 리스트에 저장 </h2>\n","  학습 데이터 -> train_x(자질화한 데이터), train_y(각 데이터의 정답 라벨)에 저장\n","  평가 데이터 -> test_x(자질화한 데이터), test_y(각 데이터의 정답 라벨)에 저장\n","  \n","  2.1 예시)\n","    train_x -> [\n","    \n","    [ { \"BOS\":True, \"EOS\":False, \"WORD\":\"나\", \"IS_DIGIT\":False, \"+1_WORD\":\"는\", \"+2_WORD\":\"사\" },\n","    { \"BOS\":False, \"EOS\":False, \"WORD\":\"는\", \"IS_DIGIT\":False, \"-1_WORD\":\"나\", \"+1_WORD\":\"사\", \"+2_WORD\":\"과\" },\n","    { \"BOS\":False, \"EOS\":False, \"WORD\":\"사\", \"IS_DIGIT\":False, \"-2_WORD\":\"나\", \"-1_WORD\":\"는\", \"+1_WORD\":\"과\", \"+2_WORD\":\"가\" }, ... ],\n","    \n","    [ ... ],\n","    \n","    ...\n","    \n","    ]\n","    \n","    train_y -> [\n","    \n","    [ \"B\", \"I\", \"B\", \"I\", \"I\", \"B\", \"I\" ],\n","    \n","    [ ... ],\n","    \n","    ...\n","    \n","    \n","    ]\n","\n","</pre>"]},{"cell_type":"code","metadata":{"id":"UHfwBbtqSgAx"},"source":["#sentence를 feature 변경하는 함수\n","\"\"\"\n","내가 관측하지 않은 값은 uniform하게 주기 -> 엔트로피의 최대화하게 설정\n","관측한 것은 그 확률 그대로 하게 할 것\n","결국 총합은 1이 되도록 유도\n","\n","MEMM은 해당 state를 관련 feature로 확률을 구하는데 해당 feature에 앞뒤 문맥을 포함한 정보를 추가해서 방향성 유지\n","그런데 label bias 문제를 해결해야함. 이는 local하게 정규화하기에 발생\n","따라서 방향성을 없애서 CRFs로 해결!\n","\"\"\"\n","def sent2feature(eumjeol_sequence):\n","  features = []\n","  sequence_length = len(eumjeol_sequence)\n","  for index, eumjeol in enumerate(eumjeol_sequence):#enumerate로 인덱스와 해당 음절을 튜플로 가져옴\n","    #이제 feature를 모델링하자\n","    #예를들면 앞에 \"이 있으면 B라고 할 수 있음\n","      feature = { \"BOS\":False, \"EOS\":False, \"WORD\":eumjeol, \"IS_DIGIT\":eumjeol.isdigit() }\n","      if (index == 0):\n","        feature[\"BOS\"]=True\n","      elif (index == sequence_length-1):\n","        feature[\"EOS\"]=True\n","\n","      if (index-1 >= 0):\n","        feature[\"-1_WORD\"] = eumjeol_sequence[index-1]#해당 음절 앞에 있는 것\n","      if (index-2 >= 0):\n","        feature[\"-2_WORD\"] = eumjeol_sequence[index-2]#해당 음절 앞앞에 있는 것\n","\n","      if (index+1 <= sequence_length-1):\n","              feature[\"+1_WORD\"] = eumjeol_sequence[index+1]#해당 음절 뒤에 있는 것\n","      if (index+2  <= sequence_length-1):\n","              feature[\"+2_WORD\"] = eumjeol_sequence[index+2]#해당 음절 뒤뒤에 있는 것\n","\n","      features.append(feature)\n","\n","  return features\n","\n","#데이터 생성\n","train_x, train_y = [], []\n","for eumjeol_sequence, label in train_datas: #train data에서\n","    train_x.append(sent2feature(eumjeol_sequence))#해당 음절을 feature화해서 입력 데이터에 넣기\n","    train_y.append(label)\n","\n","test_x, test_y = [], []\n","for eumjeol_sequence, label in test_datas:\n","    test_x.append(sent2feature(eumjeol_sequence))\n","    test_y.append(label)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qYwRX9Vdn5-D"},"source":["<h2> 1. train_x, train_y를 이용하여 crf 모델 학습 </h2>"]},{"cell_type":"code","metadata":{"id":"odbrhxSKStT-"},"source":["#crf = sklearn_crfsuite.CRF(\n","#        algorithm='lbfgs',\n","#        c1=0.1,\n","#        c2=0.1,\n","#        max_iterations=100,\n","#        all_possible_transitions=True\n","#    )\n","\n","#CRFs 학습\n","crf = sklearn_crfsuite.CRF()\n","try:\n","    crf.fit(train_x, train_y)\n","except AttributeError:\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"07BbK76nuZVK"},"source":["<pre>\n","<h2> 1. 학습한 모델을 test_x 데이터를 사용하여 평가 </h2>\n","<h2> 2. 성능 측정 </h2>\n","  2.1 metrics.flat_accuracy_score(x, y) 함수를 이용하여 성능 측정\n","    metrics.flat_accuracy_score(x, y)\n","  args\n","    x : 실제 정답 라벨이 있는 리스트\n","    y : 모델의 출력 라벨이 있는 리스트\n","  return :\n","    accuract 성능\n","  \n","<h2> 3. 모델의 출력 값과 정답 값을 이용하여 음절만으로 구성된 완전한 문장으로 변형 </h2>\n","  3.1 test_datas, pred_y 예시\n","    test_datas = [\n","    ( [\"나\", \"는\", \"사\", \"과\", \"가\", \"좋\", \"아\"], [\"B\", \"I\", \"B\", \"I\", \"I\", \"B\", \"I\"] ),\n","    \n","    ( ... ),\n","    \n","    ...\n","    \n","    ]\n","    \n","    pred_y = [\n","    \n","    [\"B\", \"B\", \"B\", \"I\", \"I\", \"I\", \"I\"],\n","    \n","    [ ... ],\n","    \n","    ...\n","    \n","    ]\n","    \n","    위의 문장을 기준으로한 변형 예시\n","    \n","    \"나\", \"는\", \"사\", \"과\", \"가\", \"좋\", \"아\" -> 나는 사과가 좋아 (정답 기준으로 변형)\n","    \"나\", \"는\", \"사\", \"과\", \"가\", \"좋\", \"아\" -> 나 는 사과가좋아 (모델 출력 기준으로 변형)\n","  \n","  3.2 최종 출력 예시\n","  \n","    정답 문장 : 1914- 18년의 전쟁은 인류를 통합시킨 최초의 공통분모였다.\n","    출력 문장 : 19 14- 18년의 전쟁은 인류를 통합시킨 최초의 공통 분모였다.\n","\n","    정답 문장 : 하지만 이 전쟁은 죽음을 통해 인류를 통합시켰다.\n","    출력 문장 : 하지만이 전쟁은 죽음을 통해 인류를 통합시켰다.\n","\n","    정답 문장 : 사라예보에서 한 세르비아인이 쏜 총 한발이 합스부르크가의 계승자를 죽였다.\n","    출력 문장 : 사라 예보에서 한세르비아인이 쏜총한 발이 합스부르크가의 계승자를 죽였다.\n","    \n","    ...\n","  \n","  \n","</pre>\n"]},{"cell_type":"code","metadata":{"id":"hgIPGK--SzmA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696675074998,"user_tz":-540,"elapsed":763,"user":{"displayName":"이주형","userId":"07579585688851948048"}},"outputId":"b844b6cc-ac6a-421f-f274-a6956ea266ae"},"source":["#CRFs 평가\n","\n","#매개변수로 테스트 데이터와 예측한 데이터 넣기\n","def show_predict_result(test_datas, predict):\n","  for index_1 in range(len(test_datas)):\n","      eumjeol_sequence, correct_labels = test_datas[index_1]#정답 레이블인 gold label\n","      predict_labels = predict[index_1]#예측 레이블\n","\n","      correct_sentence, predict_sentence = \"\", \"\"#문자열 초기화\n","      for index_2 in range(len(eumjeol_sequence)):#음절 시퀀스만큼 반복\n","          if(index_2 == 0):#첫 번째라는 것이기에 음절 시퀀스의 인덱스에 해당하는 것을 그대로 붙여넣기(assign)\n","              correct_sentence += eumjeol_sequence[index_2]\n","              predict_sentence += eumjeol_sequence[index_2]\n","              continue\n","\n","          if(correct_labels[index_2] == \"B\"):#gold label이 B이면 앞에 space 추가하고 음절 그대로 붙이기\n","              correct_sentence += \" \"\n","          correct_sentence += eumjeol_sequence[index_2]\n","\n","          if (predict_labels[index_2] == \"B\"):#예측 label이 B이면 앞에 space 추가하고 음절 그대로 붙이기\n","              predict_sentence += \" \"\n","          predict_sentence += eumjeol_sequence[index_2]\n","\n","      print(\"정답 문장 : \" + correct_sentence)\n","      print(\"출력 문장 : \" + predict_sentence)\n","      print()\n","\n","predict = crf.predict(test_x)#predict() 메서드로 평가 즉, CRFs 실행\n","#predict 변수에 예측 결과를 리턴\n","\n","print(\"Accuracy score : \" + str(metrics.flat_accuracy_score(test_y, predict)))\n","print()\n","\n","print(\"10개의 데이터에 대한 모델 출력과 실제 정답 비교\")\n","print()\n","\n","show_predict_result(test_datas[:10], predict[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy score : 0.9025812470844348\n","\n","10개의 데이터에 대한 모델 출력과 실제 정답 비교\n","\n","정답 문장 : (이름) 보내고 (이름)?… '텍사스 비전과 일치'(美 매체)\n","출력 문장 : (이름) 보내고 (이름)?…'텍사 스비전과 일치 '(美 매체)\n","\n","정답 문장 : [올림픽] 8강전 장소도 고지대, (이름)호 예방주사 잘 맞았다\n","출력 문장 : [올림픽] 8강전장소도 고지대, (이름) 호예방 주사 잘 맞았다\n","\n","정답 문장 : 롯데 (이름) 신발 보답 약속 '잘하고 나서 생각해볼게요'\n","출력 문장 : 롯데 (이름) 신발보 답약속 '잘하고 나서 생각해볼게요'\n","\n","정답 문장 : ks 2차전 '주목!\n","출력 문장 : ks 2차전 '주목!\n","\n","정답 문장 : [프로야구] po 1차전 매진…ps 7경기 중 6g 만원 관중\n","출력 문장 : [프로야구] po 1차 전매진…ps 7경기중 6g 만원 관중\n","\n","정답 문장 : 평창조직위, 19일 야구장 찾아 '2018 평창 데이' 개최\n","출력 문장 : 평창 조직위, 19일 야구장 찾아' 2018 평창데이' 개최\n","\n","정답 문장 : 넥센 '(이름) 악플러 고소?..\n","출력 문장 : 넥센' (이름) 악플러 고소?..\n","\n","정답 문장 : 넥센, 롯데전 앞두고 (이름) 1군 말소 '홍성갑 첫 콜업'\n","출력 문장 : 넥센, 롯데전 앞두고 (이름) 1군 말소' 홍성갑 첫 콜업'\n","\n","정답 문장 : '벼락 중거리슛‘ 강원 (이름), k리그1 8라운드 mvp\n","출력 문장 : '벼락 중거리슛 ‘강원 (이름), k리그 18라운드 mvp\n","\n","정답 문장 : '고메스 결승골' 아르헨, 파라과이 1-0 격파…3경기 무패 이어가(종합)\n","출력 문장 : '고메스 결승골 '아르헨, 파라과이 1-0격파…3경기 무패이어가(종합)\n","\n"]}]},{"cell_type":"code","metadata":{"id":"8AhEpssxTBzm"},"source":[],"execution_count":null,"outputs":[]}]}